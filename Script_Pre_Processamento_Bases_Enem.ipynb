{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7caaca54",
   "metadata": {},
   "source": [
    "# Script de pré-processamento para as bases de dados do ENEM\n",
    "\n",
    "**Autor**: Rafael Victor Araujo Bernardes - rafaelvictor.bernardes@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f89c6d",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "O seguinte _script_ tem como propósito realizar a preparação dos dados para a subsequente aplicação dos métodos de clusterização e seleção de atributos propostos em meu Trabalho de Conclusão de Curso (TCC). Para tanto, o _script_ realizará sequencialmente o processamento e as transformações dos dados. O processamento dos dados é uma etapa que tem como objetivo geral limpar, corrigir ou remover dados inconsistentes, verificar dados ausentes ou incompletos e identificar anomalias (_outliers_). Já o processo de transformação dos dados visa realizar a normalização, agregação, criação de novos atributos, redução e sintetização dos dados, entre outros. Estas etapas correspondem, respectivamente, à segunda e à terceira etapa do método _Knowledge Discovery in Databases_ (KDD) de Fayyad et al. (1996).\n",
    "\n",
    "A princípio, o código aqui desenvolvido será aplicado nas bases de dados do ENEM referentes aos anos de 2022, 2020 e 2019. A escolha desses anos deve-se à alta correção dos atributos presentes nessas bases. Além disso, cada um desses anos está correlacionado a algum evento histórico cujo impacto na distribuição dos dados deseja-se investigar.\n",
    "\n",
    "Espera-se que ao final da execução deste script, todas as bases alvo sejam transformada em bases menores, corrigidas, normalizadas e preparadas para aplicação de outras tecnicas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e6b9eb",
   "metadata": {},
   "source": [
    "## Importação dos dados e recursos necessários\n",
    "\n",
    "As bases de dados utilizadas para o desenvolvimento deste trabalho (microdados) podem ser encontradas no portal do Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira (INEP), o órgão responsável pelo ENEM, através do link: https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/microdados/enem.\n",
    "\n",
    "Cada microdado, por seu turno, contêm uma variedade de informações sobre os participantes coletadas ao longo de todo o processo do exame. Ao realizar o download, os usuários encontrarão não apenas a própria base de dados, mas também as provas, gabaritos, informações sobre questões, notas, questionários respondidos pelos inscritos, documentos técnicos e, acima de tudo, um extenso dicionário relacionado ao conjunto de dados. Este dicionário se mostra especialmente relevante para o desenvolvimento deste trabalho uma vez que ele caracteriza objetivamente todas as colunas presentes na base de dados.\n",
    "\n",
    "Vale ressaltar que os microdados estão formatados em arquivos de extesão \".csv\" e, para os anos selecionados, cada tabela contêm cerca de 76 colunas. Devido à grande quantidade de colunas e à diversidade de possíveis respostas que cada coluna pode conter, torna-se inviável realizar uma caracterização completa da base neste trabalho. No entanto, todas as colunas relevantes para o desenvolvimento desta pesquisa terão seus significados explorados em momentos oportunos. Recomenda-se a leitura dos dicionários de dados referêntes aos anos propostos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aadea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7112ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import category_encoders as ce\n",
    "from category_encoders.one_hot import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093e0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET_ENEM_PATH = 'D:\\Bases\\MICRODADOS_ENEM_2019.csv'\n",
    "# DATASET_ENEM_PATH = 'D:\\Bases\\MICRODADOS_ENEM_2020.csv'\n",
    "DATASET_ENEM_PATH = 'D:\\Bases\\MICRODADOS_ENEM_2022.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06a30cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "microdadosEnem = pd.read_csv(DATASET_ENEM_PATH, sep=';', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d498e0",
   "metadata": {},
   "source": [
    "## Análise exploratória dos dados.\n",
    "\n",
    "O objetivo principal desta análise exploratória dos dados é entender e extrair _insights_ iniciais sobre os microdados por meio da observação de padrões, tendências, relações e anomalias. Segue abaixo um compilado das etapas que segui:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c464f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contato inicial com a base\n",
    "\n",
    "microdadosEnem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f05399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando as dimensões da base\n",
    "\n",
    "microdadosEnem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf86ee7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizando as colunas da base\n",
    "\n",
    "microdadosEnem.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395a9cf5",
   "metadata": {},
   "source": [
    "## Pré-processamento dos dados\n",
    "\n",
    "O objetivo principal deste pré-processamento dos dados é preparar e otimizar os dados brutos para análise ou modelagem, visando melhorar a qualidade, a eficácia e a eficiência das etapas subsequentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120465cf",
   "metadata": {},
   "source": [
    "### Eliminando características individuais, de baixa variância ou inexpressivas.\n",
    "\n",
    "Por meio do dicionário de dados, sabe-se que as colunas abaixo possuem pouca relevância para o objetivo da análise. Isto porque algumas delas possuem variância igual a zero (como é o caso da coluna \"NU_ANO\" que estará sempre preenchida com o ano de realização da prova) e outras representam caracteristicas altamente individuais dos candidatos e, portanto, não são aptas para avaliação de nenhum tipo de tendência (como é o caso das colunas com prefixo \"TX_\" que são os vetores com as respostas objetivas para as diferentes áreas de conhecimento da prova de cada candidato). Há ainda um conjunto de colunas inexpressivas que tratam sobre a cor de prova do participante. Todas elas serão removidas.\n",
    "\n",
    "* \"NU_INSCRICAO\" - Número de inscrição (Individual),\n",
    "* \"NU_ANO\" - Ano do Enem (Variância Zero),\n",
    "* \"TX_RESPOSTAS_CN\" - Vetor com as respostas da parte objetiva da prova de Ciências da Natureza (Individual),\n",
    "* \"TX_RESPOSTAS_CH\" - Vetor com as respostas da parte objetiva da prova de Ciências Humanas (Individual),\n",
    "* \"TX_RESPOSTAS_LC\" - Vetor com as respostas da parte objetiva da prova de Linguagens e Códigos (Individual),\n",
    "* \"TX_RESPOSTAS_MT\" - Vetor com as respostas da parte objetiva da prova de Matemática (Individual),\n",
    "* \"TX_GABARITO_CN\" - Vetor com o gabarito da parte objetiva da prova de Ciências da Natureza (Individual),\n",
    "* \"TX_GABARITO_CH\" - Vetor com o gabarito da parte objetiva da prova de Ciências Humanas (Individual),\n",
    "* \"TX_GABARITO_LC\" - Vetor com o gabarito da parte objetiva da prova de Linguagens e Códigos (Individual),\n",
    "* \"TX_GABARITO_MT\" - Vetor com o gabarito da parte objetiva da prova de Matemática (Individual),\n",
    "* \"CO_PROVA_CN\" - Código do tipo de prova de Ciências da Natureza (Inexpressivo),\n",
    "* \"CO_PROVA_CH\" - Código do tipo de prova de Ciências Humanas (Inexpressivo),\n",
    "* \"CO_PROVA_LC\" - Código do tipo de prova de Linguagens e Códigos (Inexpressivo),\n",
    "* \"CO_PROVA_MT\" - Código do tipo de prova de Matemática (Inexpressivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a75328",
   "metadata": {},
   "outputs": [],
   "source": [
    "microdadosEnem.drop(columns=[\n",
    "    'NU_INSCRICAO',\n",
    "    # 'NU_ANO', - Vai ser removido um pouco mais adiante\n",
    "    'TX_RESPOSTAS_CN',\n",
    "    'TX_RESPOSTAS_CH',\n",
    "    'TX_RESPOSTAS_LC',\n",
    "    'TX_RESPOSTAS_MT',\n",
    "    'TX_GABARITO_CN',\n",
    "    'TX_GABARITO_CH',\n",
    "    'TX_GABARITO_LC',\n",
    "    'TX_GABARITO_MT',\n",
    "    'CO_PROVA_CN',\n",
    "    'CO_PROVA_CH',\n",
    "    'CO_PROVA_LC',\n",
    "    'CO_PROVA_MT'\n",
    "], inplace=True)\n",
    "\n",
    "microdadosEnem.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d464913",
   "metadata": {},
   "source": [
    "### Eliminando redundâncias\n",
    "\n",
    "Além disso, irei eliminar colunas redundantes.\n",
    "\n",
    "Exemplo: \"NO_MUNICIPIO_RESIDENCIA\" (nome do município) equivalente a \"CO_MUNICIPIO_RESIDENCIA\" (código do município)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daca0399",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "microdadosEnem.drop(columns=[\n",
    "    'NO_MUNICIPIO_ESC','CO_UF_ESC','SG_UF_ESC', # Todas estas colunas são iguais à CO_MUNICIPIO_ESC\n",
    "    'NO_MUNICIPIO_PROVA','CO_UF_PROVA','SG_UF_PROVA', # Todas estas colunas são iguais à CO_MUNICIPIO_PROVA\n",
    "    'TP_ANO_CONCLUIU' # Ano de Conclusão do Ensino Médio - Essa informação pode ser mais facilmente extraída da coluna TP_ST_CONCLUSAO\n",
    "], inplace=True)\n",
    "\n",
    "microdadosEnem.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec94ca1",
   "metadata": {},
   "source": [
    "### Tratamento de dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e9df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se existem valores nulos\n",
    "\n",
    "microdadosEnem.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558bdf06",
   "metadata": {},
   "source": [
    "True == A base contém dados nulos;\n",
    "False == A base não contém dados nulos \n",
    "\n",
    "Para lidar com os dados ausentes no _dataset_, uma possível abordagem seria remover todas as linhas que contenham quaisquer valores nulos. Ao final deste processo, haveria um conjunto de dados compostos apenas por linhas que possuem todas as colunas preenchidas.\n",
    "\n",
    "Apesar da simplicidade de implementação desta técnica, esta abordagem se mostrou inviável devido a alta perda de informações. Ao realizar um estudo de caso nas bases propostas, pude perceber que a implementação desta técnica ocarionaria na perda média de 70% dos registros presentes nas bases de dados.\n",
    "\n",
    "Desse modo, será necessário adotar estratégias específicas para tratar cada coluna que contém valores nulos.\n",
    "Primeiro é necessário compreender onde estão os valores nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba774c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando onde estão os valores nulos\n",
    "\n",
    "microdadosEnem.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab5338c",
   "metadata": {},
   "source": [
    "##### ESTRATÉGIAS:\n",
    "\n",
    "1. É possivel observar que há uma quantidade significativa de registros com informações ausentes relacionadas à **escola do candidato**. São elas:\n",
    "\n",
    "    * \"CO_MUNICIPIO_ESC\" (Código do município da escola);\n",
    "    * \"TP_DEPENDENCIA_ADM_ESC\" (Dependência administrativa da escola);\n",
    "    * \"TP_LOCALIZACAO_ESC\" (Tipo de localização da escola); \n",
    "    * \"TP_SIT_FUNC_ESC\" (Situação de funcionamento da escola);\n",
    "    * \"TP_ENSINO\" (Tipo de instituição de ensino);\n",
    "\n",
    "Acredita-se que estas informações relacionadas a escola do candidato não eram de preenchimento obrigatório no momento cadastro do participante no exame. Isto justificaria a grande ausência de informações.\n",
    "\n",
    "Dado que aproximadamente 70% das linhas da tabela total não possuem esses valores preenchidos, vou optar por remover essas colunas do modelo, pois não será possivel utiliza-las como objeto de ánalise confiável e nem fazer nenhum outro tipo de inferência preditiva ou classificativa.\n",
    "\n",
    "Sendo assim, nenhum tipo de inferência ou analise sobre a escola do candidato será feita, mas conseguiremos preservar 70% a mais de dados.\n",
    "\n",
    "_Uma sugestão de trabalho para o futuro é fazer analises relacionadas justamente as escolas dos participantes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo as colunas não confiáveis\n",
    "\n",
    "microdadosEnem.drop(columns=[\n",
    "    'CO_MUNICIPIO_ESC',\n",
    "    'TP_DEPENDENCIA_ADM_ESC',\n",
    "    'TP_LOCALIZACAO_ESC',\n",
    "    'TP_SIT_FUNC_ESC',\n",
    "    'TP_ENSINO'\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047da996",
   "metadata": {},
   "source": [
    "2. As colunas relacionadas as notas dos participantes também demonstram ter uma quantidade grande de dados nulos. \n",
    "\n",
    "Acredita-se que estas colunas possuam registros vazios devido a ausência do candidato no dia de aplicação do exame. Desta forma, **vou optar por prosseguir apenas com os participantes presentes nos dois dias de aplicação da prova**.\n",
    "\n",
    "Ao optar por isto, é fato que estarei reduzindo minha quantidade de registros, mas poderei também descartar as colunas relacionadas a presença dos candidatos e simplificar meu modelo.\n",
    "\n",
    "(Estas colunas deverão ter variância zero. Ou seja, apenas candidatos presentes)\n",
    "\n",
    "_Uma sugestão de trabalho para o futuro é fazer a analise justamente destas linhas que estou desconsiderando._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0f5473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo participantes ausêntes por meio da análise das notas\n",
    "\n",
    "microdadosEnem.dropna(subset=['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3b65d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validando se realmente posso remover as colunas de presença por meio da análise de variância.\n",
    "\n",
    "colunasDePresença = ['TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC', 'TP_PRESENCA_MT']\n",
    "microdadosEnem[colunasDePresença].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d11d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que a hipotese foi validada, posso remover as colunas de presença para simplificar meu modelo\n",
    "\n",
    "microdadosEnem.drop(columns=colunasDePresença, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7e4ab7",
   "metadata": {},
   "source": [
    "##### REAVALIAÇÃO DA CONSISTÊNCIA DOS DADOS:\n",
    "\n",
    "Se tudo tiver ocorrido conforme o planejado, não devem ter mais dados nulos na tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9832a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "microdadosEnem.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91a6851",
   "metadata": {},
   "source": [
    "## Transformação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e954deb5",
   "metadata": {},
   "source": [
    "Esta pesquisa visa realizar uma análise histórica das bases de dados do ENEM e identificar tendências temporais nas características de candidatos quando dividios em _clusters_.\n",
    "\n",
    "Em outras palavras, queremos entender se as caracteristicas relacionadas a _clusters_ de candidatos com predominância de notas baixas e altas se alterou ao longo do tempo.\n",
    "\n",
    "Dessa forma, é necessário adotar uma forma simples para mensurar se a nota do partipante foi alta ou baixa. Isso será de grande importância para realização das analises quando os candidados estiverem clusterizados.\n",
    "\n",
    "A estratégia adotada será a de criação de uma nova coluna que contenha a média simples de todas as notas que o candidato obteve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bde5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "microdadosEnem['MEDIA_NOTAS'] = (\n",
    "    microdadosEnem.NU_NOTA_CN +\n",
    "    microdadosEnem.NU_NOTA_CH +\n",
    "    microdadosEnem.NU_NOTA_LC +\n",
    "    microdadosEnem.NU_NOTA_MT +\n",
    "    microdadosEnem.NU_NOTA_REDACAO\n",
    ")/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31770085",
   "metadata": {},
   "outputs": [],
   "source": [
    "microdadosEnem.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda1a358",
   "metadata": {},
   "source": [
    "Agora, seguirei com o descarte das colunas referênte as notas dos candidatos nas áreas do conhecimento, dado ques estas colunas já estão representadas na coluna de média.\n",
    "\n",
    "Além disso, removerei as colunas relacionadas as competências da redação, dado que estas colunas nada mais são que componentes já representados pela coluna de média."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b326cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "microdadosEnem.drop(columns=[\n",
    "    'NU_NOTA_CN',\n",
    "    'NU_NOTA_CH',\n",
    "    'NU_NOTA_LC',\n",
    "    'NU_NOTA_MT',\n",
    "    'NU_NOTA_REDACAO',\n",
    "    'NU_NOTA_COMP1',\n",
    "    'NU_NOTA_COMP2',\n",
    "    'NU_NOTA_COMP3',\n",
    "    'NU_NOTA_COMP4',\n",
    "    'NU_NOTA_COMP5'\n",
    "    \n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03189268",
   "metadata": {},
   "outputs": [],
   "source": [
    "microdadosEnem.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f047df0a",
   "metadata": {},
   "source": [
    "### Ajustes especificos para cada ano\n",
    "\n",
    "#### Ajustes relacionados ao ano de 2022\n",
    "\n",
    "\n",
    "1) Em 2022 a coluna \"TP_COR_RACA\" possuía uma opção a mais chamada \"Não dispõe da informação\" (Item: 6). \n",
    "\n",
    "Esta opção não existia nos anos anteriores. Acredito que seja possível normalizar os dados de 2022 para ficar mais coerente com os anos anteriores\n",
    "\n",
    "**IDEA**: Unificar com a resposta \"Não declarado\" (Item: 0)\n",
    "\n",
    "2) O ano de 2022 deixou te ter a resposta \"Exterior\" (item: 4) para a coluna \"TP_ESCOLA\"\n",
    "\n",
    "**IDEA**: Para resolver esta questão, acredito que o melhor caminho seja remover de todas as demais tabelas os alunos que preencheram a opção \"Exterior\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e385b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "primeiro_item = microdadosEnem.iloc[0]  # Obtendo o primeiro item do dataset\n",
    "\n",
    "if primeiro_item['NU_ANO'] == 2022:\n",
    "    microdadosEnem['TP_COR_RACA'].replace(6, 0, inplace=True)\n",
    "    print(\"Itens 6 substituídos por 0 na coluna TP_COR_RACA.\")\n",
    "else:\n",
    "    microdadosEnem = microdadosEnem[microdadosEnem['TP_ESCOLA'] != 4]\n",
    "    print(\"Exterior removido como opção válida para a coluna - Tipo de escola do Ensino Médio\")\n",
    "\n",
    "microdadosEnem.head()\n",
    "microdadosEnem.drop(columns=['NU_ANO'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d5d91c",
   "metadata": {},
   "source": [
    "### Tratando variáveis categóricas\n",
    "\n",
    "Necessário para que os algoritmos de clusterização e seleção de atributos funcionem corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df013a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "microdadosEnem.select_dtypes(include='object').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098fe907",
   "metadata": {},
   "source": [
    "#### Aplicação da técnica Get Dummies para tratar variáveis categóricas nominais\n",
    "\n",
    "A função get_dummies do pandas é uma abordagem comum para codificar variáveis categóricas nominais em um formato numérico mais adequado para análises estatísticas e modelagem. Ao aplicar get_dummies a uma variável categórica, o pandas cria novas colunas binárias (0 ou 1) para cada categoria única presente na variável original.\n",
    "\n",
    "Por exemplo, se você tiver uma coluna chamada \"Cor\" com categorias \"Vermelho\", \"Verde\" e \"Azul\", a função get_dummies criará três novas colunas: \"Cor_Vermelho\", \"Cor_Verde\" e \"Cor_Azul\". Cada linha terá um valor 1 na coluna correspondente à cor daquela linha e 0 nas outras colunas. Isso permite que as informações categóricas sejam tratadas como variáveis numéricas, facilitando a análise estatística e o uso em modelos de machine learning.\n",
    "\n",
    "Em resumo, a função get_dummies transforma variáveis categóricas nominais em uma representação numérica que preserva as relações entre as categorias, tornando os dados mais adequados para análises quantitativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a10d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "microdadosEnem = pd.get_dummies(microdadosEnem, columns=['TP_SEXO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239fe07a",
   "metadata": {},
   "source": [
    "#### Aplicação da técnica Ordinal Encoding para tratar variáveis categóricas ordinais\n",
    "\n",
    "O OrdinalEncoder, por sua vez, é uma técnica utilizada para codificar variáveis categóricas ordinais em valores numéricos. Este método atribui um valor numérico único a cada categoria, preservando a ordem natural das categorias.\n",
    "\n",
    "Por exemplo, se você tiver uma coluna chamada \"Educação\" com categorias \"Ensino Fundamental\", \"Ensino Médio\" e \"Graduação\", o OrdinalEncoder atribuirá os valores 0, 1 e 2, respectivamente, para essas categorias.\n",
    "\n",
    "A principal diferença entre o OrdinalEncoder e o get_dummies é que o primeiro é mais adequado para variáveis categóricas ordinais, onde a ordem das categorias possui um significado específico. Já o get_dummies é mais apropriado para variáveis categóricas nominais, onde não existe uma ordem intrínseca entre as categorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba6c88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinalEncoder = OrdinalEncoder()\n",
    "\n",
    "colunas_ordinais = [\n",
    "    'Q001', 'Q002', 'Q003', 'Q004', 'Q005', 'Q006',\n",
    "    'Q007', 'Q008', 'Q009', 'Q010', 'Q011', 'Q012', 'Q013', 'Q014',\n",
    "    'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021', 'Q022',\n",
    "    'Q023', 'Q024', 'Q025'\n",
    "]\n",
    "\n",
    "microdadosEnem[colunas_ordinais] = ordinalEncoder.fit_transform(microdadosEnem[colunas_ordinais])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fbdf4d",
   "metadata": {},
   "source": [
    "Em resumo, o OrdinalEncoder codifica variáveis categóricas ordinais em valores numéricos, enquanto o get_dummies cria colunas binárias para cada categoria única em variáveis categóricas nominais. A escolha entre essas técnicas depende da natureza das variáveis e do contexto da análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fe9b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "microdadosEnem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bb29c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "microdadosEnem.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b49d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_salvar = 'D:\\\\BASES_PRE_PROCESSADAS\\\\PRE_PROCESSADOS_ENEM_2022.csv'\n",
    "microdadosEnem.to_csv(caminho_salvar, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
